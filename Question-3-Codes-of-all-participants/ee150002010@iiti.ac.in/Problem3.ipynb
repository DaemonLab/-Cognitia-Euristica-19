{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Data extraction\n",
    "Data like **Name, Email ID, Phone No, Education** present in the resume are extracted using this sript.\n",
    "\n",
    "Resume extraction can be done in *two* ways, 1. Rule based 2. Machine learning\n",
    "The entire script broadly uses *Rule based* analysis of the data\n",
    "\n",
    "Libraries used:\n",
    "1. re(RegEx)\n",
    "2. nltk(Natural Language Toolkit)\n",
    "3. spacy(spaCy)\n",
    "4. json\n",
    "5. pandas(Pandas)\n",
    "6. enchant(PyEnchant)\n",
    "\n",
    "*About Functions*\n",
    "1. read_data(url) : \n",
    "    This function takes path of the .txt format of resume file and returns the text present in it after removing any unnecessary unicode characters like bullets etc.\n",
    "\n",
    "**The attributes Name, Email, Phone No. are assumed to be in the first 100-200 words of the resume and proceeded accordingly**\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "2. extractPhno(text) : \n",
    "    This function takes one sentence or a string and extracts Phone No. using RegEx pattern matching. Output is a list of all phone no. present in it.\n",
    "\n",
    "3. extractEmailid(text):\n",
    "    This function takes one sentence or a string and extracts Email ID using RegEx pattern matching. Output is a list of all Email IDs present in it.\n",
    "\n",
    "4. extractName(sentence): Extracts the name of the candidate. It checks with all possible Indian Names present in 'allNames.txt' which is downloded from internet, and gives the output.\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "5. extractEdu(sentences): This function is written assuming the resumes do not have any degrees other than 'Bachelors' and 'Masters' as primary **and coming from engineering domain**. This function makes use of 'education.txt' as source file to get the results.\n",
    "\n",
    "6. extractExp(sentences): A 'TechSkills.txt' file is generated with all possible technologies and used for finding them in resumes. Since these are definite, using a database is much better. The 'TechSkill.txt' can be populated with all other technologies also so that better results can be obtained.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------\n",
    "*Also if the person has mentioned a skill anywhere in resume then, that should be about some work he has done in the past which would count as an experience. So if we find these skills on any part of the document, it should be counted in, and so what the function does.*\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------\n",
    "**Due to time constraint, I couldn't populate the file, but the file still contains most popular computer skills which every programmer is expected of**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(url):\n",
    "    file = open(url, 'r')\n",
    "    data = file.read()\n",
    "    return data.encode('ascii', errors='ignore').decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPhno(text):\n",
    "    phno = []\n",
    "    pattern = re.compile(r'(([+]|\\d){10,14})')\n",
    "    entries = re.split(\"\\n\", text)\n",
    "    for entry in entries:\n",
    "        text = entry.replace(\" \", \"\")\n",
    "        text = text.replace(\"-\", \"\")\n",
    "        ans = pattern.search(text)\n",
    "        if ans is not None:\n",
    "            phno.append(ans[0][-10:])\n",
    "    return phno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEmailid(text):\n",
    "    pattern = re.compile(r'(\\w|\\d|[.])+[@](\\w+)[.](\\w+)')\n",
    "    entries = re.split(\"\\n+\", text)\n",
    "    email = []\n",
    "    for entry in entries:\n",
    "        ans = pattern.search(entry)\n",
    "        if ans is not None:\n",
    "            email.append(ans[0])\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extractName(sent):\n",
    "    sent = re.sub(r'[^a-zA-z]', ' ', sent)\n",
    "    sent = nlp(sent)\n",
    "    dictionary = enchant.Dict('en_US')\n",
    "    indian_names = set(open('allNames.txt', 'r').read().split())\n",
    "    ans = []\n",
    "    new_ans = []\n",
    "    count = 0\n",
    "    for word in sent:\n",
    "        if count==15:\n",
    "            break\n",
    "        if word.tag_=='NNP':\n",
    "            w = str(word)\n",
    "            if not dictionary.check(w.lower()):\n",
    "                new_ans.append(w)\n",
    "                if w.lower() in indian_names:\n",
    "                    ans.append(w)        \n",
    "        count+=1\n",
    "    if len(ans)==0 or len(new_ans)<3 :\n",
    "        return new_ans[:2]\n",
    "    else:\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEdu(sentences):\n",
    "    ans_edu = []\n",
    "    for sent in sentences:\n",
    "        pattern = re.compile(r'((Master of)|(Bachelor of)|(Bachelors in)|(Masters in))\\s\\w+\\s\\w+', re.IGNORECASE)\n",
    "        match = re.search(pattern, sent)\n",
    "        if match is not None:\n",
    "            temp = []\n",
    "            for w in word_tokenize(match.group()):\n",
    "                if w not in stopwords.words('english'):\n",
    "                    temp.append(w)\n",
    "            ans_edu.append(' '.join(temp))\n",
    "            continue\n",
    "        edu_list = eval('dict({})'.format(open('education.txt', 'r').read()))\n",
    "        all_words = word_tokenize(sent)\n",
    "        for word in all_words:\n",
    "            if edu_list.get(word.upper()) is not None:\n",
    "                ans_edu.append(edu_list.get(word.upper()))\n",
    "    #print(edu_list)\n",
    "    return ans_edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractExp(sentences):\n",
    "    techSkills = set(open('TechSkills.txt').read().split('\\n'))\n",
    "    ans = set()\n",
    "    for sent in sentences:\n",
    "        all_words = word_tokenize(sent)\n",
    "        for w in all_words:\n",
    "            if w.upper() in techSkills:\n",
    "                ans.add(w.upper())\n",
    "    return list(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_data('resumes/Amarnath.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "phno = extractPhno(d[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "emailid = extractEmailid(d[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amarnath']"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractName(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "education= extractEdu(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bachelors']\n"
     ]
    }
   ],
   "source": [
    "print(education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C', 'DATABASE', 'HTML', 'C++', 'SQL']"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractExp(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playground **ends here** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to different .json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resumenames = ['Abbas- MS Dyna.txt', 'Amarnath.txt', 'Arup_Kumar_H1 B_NC.txt', 'CV of Binnu Thomas.txt', 'Gangadhar Vasanthapuram_Spruce InfoTech.txt']\n",
    "count = 0\n",
    "for i in resumenames:\n",
    "    d = read_data('resumes/'+i)\n",
    "    phno = extractPhno(d[:200])\n",
    "    emailid = extractEmailid(d[:200])\n",
    "    sentences = sent_tokenize(d)\n",
    "    name = extractName(sentences[0])\n",
    "    education = extractEdu(sentences)\n",
    "    exp = extractExp(sentences)\n",
    "    output = {\n",
    "        'name' : name,\n",
    "        'email' : emailid,\n",
    "        'phone' : phno,\n",
    "        'edu' : education,\n",
    "        'exp' : exp\n",
    "    }\n",
    "    with open(i[:-4]+'.txt', 'w') as outfile:\n",
    "        json.dump(output, outfile)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
